{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b9b900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    TensorDataset,\n",
    "    Dataset\n",
    ")\n",
    "from torch.optim import (Optimizer, Adam)\n",
    "from torch.optim import SGD\n",
    "from torch import nn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8f6ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"Titanic-Dataset.csv\"\n",
    "\n",
    "# Get data in pandas dataframe\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f37158-c594-45e1-a538-b58adc94b184",
   "metadata": {},
   "source": [
    "### Step One:\n",
    "\n",
    "We start by cleaning up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "504f6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[['Survived','Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']]\n",
    "    \n",
    "    df = df.replace(\"male\", 0)\n",
    "    df = df.replace(\"female\", 1)\n",
    "    # Replace NaN\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    \n",
    "    # Get rid of blanks, get only cabin class - shows upper to lower decks, \n",
    "    # then 1-hot encode (seperate each class to binary columns)\n",
    "    # Will end up with around 8 binary columns\n",
    "    # Cabin_U = unknown\n",
    "    df['Cabin'] = df['Cabin'].fillna('Unknown')\n",
    "    df['Cabin'] = df['Cabin'].str[0]\n",
    "    df = pd.get_dummies(df, columns=['Cabin'])\n",
    "\n",
    "    # 1-hot encoding for 3 binary columns repping port of embarkment\n",
    "    df = pd.get_dummies(df, columns=['Embarked'])\n",
    "\n",
    "    bool_cols = df.select_dtypes(include='bool').columns\n",
    "    df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bdb634d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass  Sex        Age  SibSp  Parch     Fare  Cabin_A  \\\n",
      "0           0       3    0  22.000000      1      0   7.2500        0   \n",
      "1           1       1    1  38.000000      1      0  71.2833        0   \n",
      "2           1       3    1  26.000000      0      0   7.9250        0   \n",
      "3           1       1    1  35.000000      1      0  53.1000        0   \n",
      "4           0       3    0  35.000000      0      0   8.0500        0   \n",
      "..        ...     ...  ...        ...    ...    ...      ...      ...   \n",
      "886         0       2    0  27.000000      0      0  13.0000        0   \n",
      "887         1       1    1  19.000000      0      0  30.0000        0   \n",
      "888         0       3    1  29.699118      1      2  23.4500        0   \n",
      "889         1       1    0  26.000000      0      0  30.0000        0   \n",
      "890         0       3    0  32.000000      0      0   7.7500        0   \n",
      "\n",
      "     Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  Cabin_U  \\\n",
      "0          0        0        0        0        0        0        0        1   \n",
      "1          0        1        0        0        0        0        0        0   \n",
      "2          0        0        0        0        0        0        0        1   \n",
      "3          0        1        0        0        0        0        0        0   \n",
      "4          0        0        0        0        0        0        0        1   \n",
      "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "886        0        0        0        0        0        0        0        1   \n",
      "887        1        0        0        0        0        0        0        0   \n",
      "888        0        0        0        0        0        0        0        1   \n",
      "889        0        1        0        0        0        0        0        0   \n",
      "890        0        0        0        0        0        0        0        1   \n",
      "\n",
      "     Embarked_C  Embarked_Q  Embarked_S  \n",
      "0             0           0           1  \n",
      "1             1           0           0  \n",
      "2             0           0           1  \n",
      "3             0           0           1  \n",
      "4             0           0           1  \n",
      "..          ...         ...         ...  \n",
      "886           0           0           1  \n",
      "887           0           0           1  \n",
      "888           0           0           1  \n",
      "889           1           0           0  \n",
      "890           0           1           0  \n",
      "\n",
      "[891 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = clean_df(df)\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d47c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Torch dataset with tensors\n",
    "# Need to update this to split test data, ie make 10% of dataset test data, 90% is training\n",
    "def make_dataset(df: pd.DataFrame) -> Dataset:\n",
    "    features = df.drop(columns=['Survived'])\n",
    "    \n",
    "    # Ytrue\n",
    "    target = df['Survived']\n",
    "\n",
    "    x_values = torch.tensor(features.values, dtype=torch.float32)\n",
    "    y_values = torch.tensor(target.values, dtype=torch.int64)\n",
    "    return TensorDataset(x_values,y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d66ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b13c8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(dataset: Dataset, batch_size:int, shuffle:bool) -> DataLoader:\n",
    "    return DataLoader(dataset, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a6f10d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = make_dataloader(train_dataset, shuffle=False, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad171f77",
   "metadata": {},
   "source": [
    "### Step Two:\n",
    "\n",
    "We start to design our various ML models to test out and explore the performance on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa1cd0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Linear Classifier Model\n",
    "\n",
    "\"\"\"\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.linear = nn.Linear(num_features, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f5c8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Logistic Regression Model\n",
    "\n",
    "\"\"\"\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        # Makes logit\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca2e494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "1 Layer MLP Classifier Model\n",
    "\n",
    "\"\"\"\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.linear1 = nn.Linear(num_features, 100)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.output = nn.Linear(100, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2650a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "2 Layer MLP Classifier Model\n",
    "\n",
    "\"\"\"\n",
    "class MLP2DClassifier(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.linear1 = nn.Linear(num_features, 100)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(100,50)\n",
    "        self.output = nn.Linear(50,2)\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7de10a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "4 Layer Residual MLP Classifier Model\n",
    "\n",
    "\"\"\"\n",
    "class MLP4DResidualClassifier(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "        self.num_features = num_features\n",
    "\n",
    "        # Main layers\n",
    "        self.linear1 = nn.Linear(num_features, 128)\n",
    "        self.linear2 = nn.Linear(128, 64)\n",
    "        self.linear3 = nn.Linear(64, 32)\n",
    "        self.linear4 = nn.Linear(32, 16)\n",
    "\n",
    "        # Skip connections\n",
    "        self.skip1 = nn.Linear(num_features, 128)\n",
    "        self.skip2 = nn.Linear(128, 64)\n",
    "        self.skip3 = nn.Linear(64, 32)\n",
    "        self.skip4 = nn.Linear(32, 16)\n",
    "        \n",
    "        self.output = nn.Linear(16,2)\n",
    "    def forward(self, x):\n",
    "        s1 = self.skip1(x)\n",
    "        x = self.act(self.linear1(x) + s1)\n",
    "\n",
    "        s2 = self.skip2(x)\n",
    "        x = self.act(self.linear2(x) + s2)\n",
    "\n",
    "        s3 = self.skip3(x)\n",
    "        x = self.act(self.linear3(x) + s3)\n",
    "\n",
    "        s4 = self.skip4(x)\n",
    "        x = self.act(self.linear4(x) + s4)\n",
    "\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d032ba5-3056-4d3b-a969-f43755823976",
   "metadata": {},
   "source": [
    "### Step Three:\n",
    "\n",
    "We now begin to train and save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "747c4c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = train_dataset.tensors[0].shape\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acf968e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_train(model: nn.Module, loss: nn.Module, optimizer: Optimizer, dataloader: DataLoader, epochs: int):\n",
    "    for epoch in range(epochs):\n",
    "        for (x,target) in dataloader:\n",
    "            pred = model(x)\n",
    "            l = loss(pred, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            [w,b] = model.parameters()\n",
    "            print(f'epoch {epoch + 1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0588ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.142, loss = 0.59377247\n",
      "epoch 11: w = 0.146, loss = 0.57468140\n",
      "epoch 21: w = 0.146, loss = 0.56229663\n",
      "epoch 31: w = 0.145, loss = 0.55359000\n",
      "epoch 41: w = 0.144, loss = 0.54691315\n",
      "epoch 51: w = 0.143, loss = 0.54134536\n",
      "epoch 61: w = 0.143, loss = 0.53638387\n",
      "epoch 71: w = 0.143, loss = 0.53176123\n",
      "epoch 81: w = 0.143, loss = 0.52734107\n",
      "epoch 91: w = 0.144, loss = 0.52305800\n"
     ]
    }
   ],
   "source": [
    "# Training linear\n",
    "lin = LinearClassifier(n_features)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# May want to adjust learning rate\n",
    "optimizer = SGD(lin.parameters(), lr=0.001)\n",
    "# May want less epochs\n",
    "lin_train(lin, loss, optimizer, train_dataloader, n_epochs)\n",
    "torch.save(lin, \"lin_model.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f772d834-7d45-42f2-8280-247e4867f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_train(model: nn.Module, loss: nn.Module, optimizer: Optimizer, dataloader: DataLoader, epochs: int):\n",
    "    for epoch in range(epochs):\n",
    "        for x, target in dataloader:\n",
    "            target = target.float().unsqueeze(1)\n",
    "            pred = model(x)\n",
    "            l = loss(pred, target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            [w,b] = model.parameters()\n",
    "            print(f'epoch {epoch + 1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "359eafe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = -0.074, loss = 0.20454602\n",
      "epoch 11: w = -0.100, loss = 0.40410495\n",
      "epoch 21: w = -0.122, loss = 0.39756119\n",
      "epoch 31: w = -0.139, loss = 0.39344776\n",
      "epoch 41: w = -0.152, loss = 0.39111623\n",
      "epoch 51: w = -0.162, loss = 0.39008528\n",
      "epoch 61: w = -0.169, loss = 0.38999808\n",
      "epoch 71: w = -0.175, loss = 0.39059016\n",
      "epoch 81: w = -0.180, loss = 0.39166415\n",
      "epoch 91: w = -0.184, loss = 0.39307275\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic\n",
    "log = LogisticRegression(n_features)\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# May want to adjust learning rate\n",
    "optimizer = SGD(log.parameters(), lr=0.001)\n",
    "log_train(log,loss,optimizer,train_dataloader,n_epochs)\n",
    "torch.save(log, \"log_model.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "772f2ac6-417b-42be-9086-5a99e072c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_train(model: nn.Module, loss: nn.Module, optimizer: Optimizer, dataloader: DataLoader, epochs: int):\n",
    "    for epoch in range(epochs):\n",
    "        for x, target in dataloader:\n",
    "            pred = model(x)\n",
    "            l = loss(pred, target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "        if epoch % 10 == 0:\n",
    "            w = model.linear1.weight\n",
    "            print(f'epoch {epoch + 1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78345a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = -0.095, loss = 0.43417811\n",
      "epoch 11: w = -0.148, loss = 0.39460459\n",
      "epoch 21: w = -0.177, loss = 0.38648927\n",
      "epoch 31: w = -0.197, loss = 0.37094721\n",
      "epoch 41: w = -0.204, loss = 0.35725096\n",
      "epoch 51: w = -0.208, loss = 0.35009229\n",
      "epoch 61: w = -0.211, loss = 0.34017166\n",
      "epoch 71: w = -0.213, loss = 0.32246652\n",
      "epoch 81: w = -0.216, loss = 0.30527335\n",
      "epoch 91: w = -0.217, loss = 0.28432623\n"
     ]
    }
   ],
   "source": [
    "# Training MLP\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 1 layer\n",
    "mlp = MLPClassifier(n_features)\n",
    "optimizer = Adam(mlp.parameters(), lr=0.001)\n",
    "mlp_train(mlp,loss,optimizer,train_dataloader,n_epochs)\n",
    "\n",
    "torch.save(mlp, \"mlp_onelayer_model.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f0df3cd-4873-4674-91e1-6556890c919f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.121, loss = 0.47413000\n",
      "epoch 11: w = 0.119, loss = 0.38618481\n",
      "epoch 21: w = 0.120, loss = 0.36881888\n",
      "epoch 31: w = 0.108, loss = 0.34620664\n",
      "epoch 41: w = 0.078, loss = 0.33320415\n",
      "epoch 51: w = 0.042, loss = 0.31737164\n",
      "epoch 61: w = 0.012, loss = 0.30967286\n",
      "epoch 71: w = -0.006, loss = 0.29498753\n",
      "epoch 81: w = -0.016, loss = 0.27107331\n",
      "epoch 91: w = -0.022, loss = 0.26264268\n"
     ]
    }
   ],
   "source": [
    "# 2 layers\n",
    "mlp2 = MLP2DClassifier(n_features)\n",
    "optimizer = Adam(mlp2.parameters(), lr=0.001)\n",
    "mlp_train(mlp2,loss,optimizer,train_dataloader,n_epochs)\n",
    "\n",
    "torch.save(mlp2, \"mlp_twolayer_model.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee98dee9-472e-4261-bf01-d7f6e28fb590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.153, loss = 0.39594677\n",
      "epoch 11: w = 0.130, loss = 0.32388675\n",
      "epoch 21: w = 0.071, loss = 0.30200589\n",
      "epoch 31: w = 0.041, loss = 0.33498892\n",
      "epoch 41: w = 0.026, loss = 0.28398848\n",
      "epoch 51: w = 0.052, loss = 0.31911257\n",
      "epoch 61: w = 0.060, loss = 0.30112976\n",
      "epoch 71: w = 0.082, loss = 0.28604266\n",
      "epoch 81: w = 0.098, loss = 0.27376878\n",
      "epoch 91: w = 0.108, loss = 0.27897996\n"
     ]
    }
   ],
   "source": [
    "# 4 layers residual\n",
    "mlp4 = MLP4DResidualClassifier(n_features)\n",
    "optimizer = Adam(mlp4.parameters(), lr=0.001)\n",
    "mlp_train(mlp4,loss,optimizer,train_dataloader,n_epochs)\n",
    "\n",
    "torch.save(mlp4, \"mlp_fourlayer_model.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train all, whichever performs best we integrate into final game (system integration part 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
